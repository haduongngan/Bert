{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"m-xmlr-Sentiment.ipynb","provenance":[{"file_id":"1DjqY38GIZ7yN0cfvCvIVJrxbtOV3akbM","timestamp":1636596354907},{"file_id":"1Lsh3mlmybwoaOSA8hCnvVC2BOIs-TqxF","timestamp":1636516888267},{"file_id":"1wdt7z8UcDla3EAjJXI-pxmqZEEB3ry4Z","timestamp":1635951666520},{"file_id":"1bBnyzCkj2Imdk5hrZ0OAOH1l8aDLF4YW","timestamp":1635433549658}],"collapsed_sections":["ObVSjGJ2Adwi","0HtXPhT4g9VN"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6155b0f80eed456c9a886d25dbaf73a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_32f814cd1082446abefce720ef52d67a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_74c435374400457dac952b175c658cb7","IPY_MODEL_a4c5c0d0a9354741a21d93e39ff96575","IPY_MODEL_1f8050def6404f888e2f63dc6c5072e9"]}},"32f814cd1082446abefce720ef52d67a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74c435374400457dac952b175c658cb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8195e47994d24def8e282d00693edb9c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51834f5e17394c6d9cc09500184ff0b9"}},"a4c5c0d0a9354741a21d93e39ff96575":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d50dc48b246e4786bda8a23947fdfff4","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":5069051,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5069051,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4bb54036a494493b907c06e479b25d13"}},"1f8050def6404f888e2f63dc6c5072e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3705ae0221044ef3b1ff8e508d8727c6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4.83M/4.83M [00:00&lt;00:00, 8.60MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b553a3e515be4df2a1856423c2dc3163"}},"8195e47994d24def8e282d00693edb9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"51834f5e17394c6d9cc09500184ff0b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d50dc48b246e4786bda8a23947fdfff4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4bb54036a494493b907c06e479b25d13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3705ae0221044ef3b1ff8e508d8727c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b553a3e515be4df2a1856423c2dc3163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c79a8fa3a21414f9c2e12507afcc41c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e64ea438774f408fb797ef20605f389c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_638565d28f3543e689fdb433af8702d7","IPY_MODEL_eb0b064882004b13b398573a05e46d23","IPY_MODEL_82cfca53e7604b8a9a256db42beac14d"]}},"e64ea438774f408fb797ef20605f389c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"638565d28f3543e689fdb433af8702d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ee24a25ae9e5464dbb6c1883ff395795","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c56bd8840354d3d9e4926ab83b5dfb3"}},"eb0b064882004b13b398573a05e46d23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8d3c50ed94254ea2be65eb6322286ccc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9096718,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9096718,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_739d78e720ec4757bfa16147dfdb274e"}},"82cfca53e7604b8a9a256db42beac14d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c8ad38a9ea8941418c0fb8b8350abbe3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8.68M/8.68M [00:00&lt;00:00, 15.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14ad0fbda45f4a07a00f2667b72e491e"}},"ee24a25ae9e5464dbb6c1883ff395795":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1c56bd8840354d3d9e4926ab83b5dfb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d3c50ed94254ea2be65eb6322286ccc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"739d78e720ec4757bfa16147dfdb274e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c8ad38a9ea8941418c0fb8b8350abbe3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"14ad0fbda45f4a07a00f2667b72e491e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14a392244246465a9379c87329806441":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_568be31fddf54ba380bad70a8aff6a13","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c4c6e99e5a40432293afcb41b944c945","IPY_MODEL_6b85a57dacf7429a93a3f18c13da41fe","IPY_MODEL_58ea457b4c3b4c4bb792eae5e5f4c1a6"]}},"568be31fddf54ba380bad70a8aff6a13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c4c6e99e5a40432293afcb41b944c945":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_561879b1dd4d431dabf8b721a56c5d69","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9f11c16dd809439ebff49b540fb36f6b"}},"6b85a57dacf7429a93a3f18c13da41fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_216cb0d635e44711b0378a5046b70ffc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":512,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":512,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cd4351dad6e647b7a61f46ed200000ee"}},"58ea457b4c3b4c4bb792eae5e5f4c1a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b7853c3816a14e92b65db37e6d140595","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 512/512 [00:00&lt;00:00, 12.0kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c6ffd057653a4dc78be6c86c2f66f9c5"}},"561879b1dd4d431dabf8b721a56c5d69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9f11c16dd809439ebff49b540fb36f6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"216cb0d635e44711b0378a5046b70ffc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cd4351dad6e647b7a61f46ed200000ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b7853c3816a14e92b65db37e6d140595":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c6ffd057653a4dc78be6c86c2f66f9c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"37ab34d15e9440599596eefcd50f821f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f4fca351c45c4459a40faf81fea66780","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_887912e7abcd4c2098b1f06c555da743","IPY_MODEL_940f0bb356494db28404f6fc3e3737a1","IPY_MODEL_e1d218f17aa9443bb477d423d1b4d90b"]}},"f4fca351c45c4459a40faf81fea66780":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"887912e7abcd4c2098b1f06c555da743":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_89e387fca2e14f0780277e2f614c7a0d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e6dbd33a9fb4b4681e9abd976e7d2e7"}},"940f0bb356494db28404f6fc3e3737a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5919c26d058549eaba67d4c2e3a28845","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1115590446,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1115590446,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ef45cbdb95bd4e46a411f85d5b69c708"}},"e1d218f17aa9443bb477d423d1b4d90b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a553ea8e6ba64a2587a46c853f6db991","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.04G/1.04G [00:31&lt;00:00, 33.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_60533a36c4014783bbf200bfcaf55a7b"}},"89e387fca2e14f0780277e2f614c7a0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8e6dbd33a9fb4b4681e9abd976e7d2e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5919c26d058549eaba67d4c2e3a28845":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ef45cbdb95bd4e46a411f85d5b69c708":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a553ea8e6ba64a2587a46c853f6db991":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"60533a36c4014783bbf200bfcaf55a7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29e377876fe14fa7b947dc1410683b2e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fffc88bbb8a0441885dabd54aee869da","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_703cf676361b4a04ae8b8fccd35f9234","IPY_MODEL_01e34898d93a4912870a0112b0ed8d52","IPY_MODEL_77979da20e544e06b6c2720142d9c9bf"]}},"fffc88bbb8a0441885dabd54aee869da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"703cf676361b4a04ae8b8fccd35f9234":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_214ce1eea54d4c92a7f601d865b1e17a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 0: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05818affbde843938c70777addb3c7c8"}},"01e34898d93a4912870a0112b0ed8d52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_189f60a0d2074f1fbf6942e032da9a1d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_596aff5d44ba47709488e40ad40cffc5"}},"77979da20e544e06b6c2720142d9c9bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d7127067aa8446b2a37c87eeba8b8e80","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:01&lt;00:00,  1.41it/s, loss=0.697, v_num=]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bad2f6a0262c46a79ef664083d4a3735"}},"214ce1eea54d4c92a7f601d865b1e17a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"05818affbde843938c70777addb3c7c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"189f60a0d2074f1fbf6942e032da9a1d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"596aff5d44ba47709488e40ad40cffc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7127067aa8446b2a37c87eeba8b8e80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bad2f6a0262c46a79ef664083d4a3735":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d1052edc66745d489b8e0521b6196dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4e261c2145d94359bc6e802cd403bd50","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ab646c647ef94928a8549ebdbd214c19","IPY_MODEL_4f19dd24b1934551835ccdccfec60248","IPY_MODEL_ff1a1c027d6c4ca9a6f2d153643f6e10"]}},"4e261c2145d94359bc6e802cd403bd50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"ab646c647ef94928a8549ebdbd214c19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_68ca4b3edb4f4998a49f37a0d36d352b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_008222609e8e44218dd7a2e1d77de8ba"}},"4f19dd24b1934551835ccdccfec60248":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d486464353dd4a8c8c2b90c329842cf2","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4f50bad9552143ed91b928b74fc966a6"}},"ff1a1c027d6c4ca9a6f2d153643f6e10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6a73d5f9f1c54bec8f92e5d4bf9aa325","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/1 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a3611fdf5aeb4d9492a1008d985c7217"}},"68ca4b3edb4f4998a49f37a0d36d352b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"008222609e8e44218dd7a2e1d77de8ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d486464353dd4a8c8c2b90c329842cf2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4f50bad9552143ed91b928b74fc966a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a73d5f9f1c54bec8f92e5d4bf9aa325":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a3611fdf5aeb4d9492a1008d985c7217":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cf56bf3884364c88abc45e2844c4c590":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ce3b2765eeb74a65a6b8137cecb0980f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_806831da7e754f3d993d023f0228d928","IPY_MODEL_0250cd1f5abd46beb22d6ba40c03f2c3","IPY_MODEL_5ca8efe737c94f8dac665ee11ae020a2"]}},"ce3b2765eeb74a65a6b8137cecb0980f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"806831da7e754f3d993d023f0228d928":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2dcdac74c6724a5a855caacc57e07d97","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validation sanity check:   0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_56c26b2b432f4236a3b4efc65b04483c"}},"0250cd1f5abd46beb22d6ba40c03f2c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1da5dd29fbb34d63983611f79568008e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5571eb5d60646f3813f4963476ba22a"}},"5ca8efe737c94f8dac665ee11ae020a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_88e1d48b28614d4090e45495c4e123e6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/2 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_61d3604ced8a43878bc9e16d075f4238"}},"2dcdac74c6724a5a855caacc57e07d97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"56c26b2b432f4236a3b4efc65b04483c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1da5dd29fbb34d63983611f79568008e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f5571eb5d60646f3813f4963476ba22a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88e1d48b28614d4090e45495c4e123e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"61d3604ced8a43878bc9e16d075f4238":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b4128aad184e4d4c9174d40b5ea3efbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_454f0255b64b4b9b9dbe9bd897f4b404","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_88b0cbe04174484abe78dcb92eada40e","IPY_MODEL_6971e5e5539343769cb9130075e7da8b","IPY_MODEL_23d8a90366fa4193a893cecadc6546eb"]}},"454f0255b64b4b9b9dbe9bd897f4b404":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"88b0cbe04174484abe78dcb92eada40e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_796fa4f92e5841b5a1f397e1179691e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Epoch 0:  50%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_559fe0e992d94b99b8a9d90f5a9296cc"}},"6971e5e5539343769cb9130075e7da8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1e42b6d01e4847858780b0c1e05a145f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":6075,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3040,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_70e0c948b8fe422a8f63ed67cdf0ce65"}},"23d8a90366fa4193a893cecadc6546eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7eb73ed1cca34e2fa27d160c754af53d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3040/6075 [26:27&lt;26:24,  1.92it/s, loss=0.545, v_num=3]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89683f285640422cba03e66b8332e643"}},"796fa4f92e5841b5a1f397e1179691e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"559fe0e992d94b99b8a9d90f5a9296cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1e42b6d01e4847858780b0c1e05a145f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"70e0c948b8fe422a8f63ed67cdf0ce65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7eb73ed1cca34e2fa27d160c754af53d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89683f285640422cba03e66b8332e643":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bbc7190d1fed42e8b76dacdf4887a5c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_23c113c9a9e0424da3cbf764fdfe823f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ffeba23680074b52a45ef976f323dea3","IPY_MODEL_73e2c3f57aa246b7adc6d25d9736c8da","IPY_MODEL_edbb856bb3fc4a6d97b820deb94238f1"]}},"23c113c9a9e0424da3cbf764fdfe823f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"ffeba23680074b52a45ef976f323dea3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b333fd5b10d8434eb56d3ba68220d14b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Validating: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4fd80b5bf00e4b9caf2deef785685721"}},"73e2c3f57aa246b7adc6d25d9736c8da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d8ec5cb8221b4f1f820bd32991a9e834","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":2700,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2700,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dbd856365a0543eabd303a63de8951cb"}},"edbb856bb3fc4a6d97b820deb94238f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b8ca3b1c912d43f1ac9c09ada3126362","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2700/2700 [18:21&lt;00:00,  2.45it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6090a32fc8d14884a23a16a374a4be8a"}},"b333fd5b10d8434eb56d3ba68220d14b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4fd80b5bf00e4b9caf2deef785685721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8ec5cb8221b4f1f820bd32991a9e834":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dbd856365a0543eabd303a63de8951cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8ca3b1c912d43f1ac9c09ada3126362":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6090a32fc8d14884a23a16a374a4be8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"5zqn-9fMUMrc"},"source":["## Install dependences\n","- pytorch-lightning: a simple trainer to help you minize code base\n","- transformers: library contains multiple BERT models\n","- sentencepiece: a word-to-vect library with fast implementation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9uVlPq0rUeIO","executionInfo":{"status":"ok","timestamp":1637998117911,"user_tz":-420,"elapsed":24003,"user":{"displayName":"Toàn Trần Quang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10017393319087150177"}},"outputId":"b766513a-dc9f-4a17-be74-c2b704c1f48b"},"source":["!pip install pytorch-lightning\n","!pip install transformers\n","!pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.5.3-py3-none-any.whl (523 kB)\n","\u001b[K     |████████████████████████████████| 523 kB 12.9 MB/s \n","\u001b[?25hCollecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 51.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.7.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.10.0.2)\n","Collecting pyDeprecate==0.3.1\n","  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n","Collecting PyYAML>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 33.3 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.10.0+cu111)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 54.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n","Collecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n","\u001b[K     |████████████████████████████████| 329 kB 56.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 41.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.42.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.7)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.2.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n","\u001b[K     |████████████████████████████████| 192 kB 48.7 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 41.9 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 52.1 MB/s \n","\u001b[?25hBuilding wheels for collected packages: future\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=2536ee110061cd724bd9ba8fe89df5f799da6e75fdedadbfe6fdcc5ef4f9d3ce\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built future\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, future, pytorch-lightning\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 frozenlist-1.2.0 fsspec-2021.11.1 future-0.18.2 multidict-5.2.0 pyDeprecate-0.3.1 pytorch-lightning-1.5.3 torchmetrics-0.6.0 yarl-1.7.2\n","Collecting transformers\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 12.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 36.9 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n","\u001b[K     |████████████████████████████████| 59 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 38.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.1.2 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 12.0 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}]},{"cell_type":"code","metadata":{"id":"PCDyJwo0UnIk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637998139649,"user_tz":-420,"elapsed":21780,"user":{"displayName":"Toàn Trần Quang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10017393319087150177"}},"outputId":"80b20263-1b39-4380-8abf-c6721f02256c"},"source":["# mount to your drive and access your dataset\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"ObVSjGJ2Adwi"},"source":["# LOAD DATA"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5tPeRinVUmh","executionInfo":{"status":"ok","timestamp":1637998140692,"user_tz":-420,"elapsed":1054,"user":{"displayName":"Toàn Trần Quang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10017393319087150177"}},"outputId":"51256f20-4368-44d7-f29b-c870804d5043"},"source":["# replace this path to your dataset directory\n","DATA_ROOT_DIR=\"/content/drive/MyDrive/Colabs/shopee-sentiment\"\n","!ls $DATA_ROOT_DIR"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_submission.csv  train.csv\t     train_preprocess_unsegment.csv\n","test.csv\t       train.gsheet\n","test_preprocess.csv    train_preprocess.csv\n"]}]},{"cell_type":"code","metadata":{"id":"T-95Em2MAchd"},"source":["# include some dependence\n","import pandas as pd\n","import numpy as np\n","from torch.utils.data import random_split, DataLoader, Dataset\n","import pytorch_lightning as pl\n","import torch.nn as nn\n","import torch\n","import time\n","\n","# custom retio\n","train_ratio = 0.2\n","\n","DATA_DIR = '/content/drive/MyDrive/Colabs/train_preprocess.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"pk6fOTGRhDUb","executionInfo":{"status":"ok","timestamp":1637998150690,"user_tz":-420,"elapsed":1251,"user":{"displayName":"Toàn Trần Quang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10017393319087150177"}},"outputId":"ac9d04d1-5729-4fea-c46f-abb027489dfc"},"source":["# Use pandas to read csv, this will return a excel like table data\n","train = pd.read_csv(DATA_DIR,usecols=['preprocess_text', 'class']).dropna()\n","train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class</th>\n","      <th>preprocess_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>đến quán 2 lần thôi rất là thích quán tuy nằm ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>đến quán vào tối chủ_nhật có band hát khá ổn t...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>phục_vụ lâu quá mặc_dù khách rất vắng đợi gần ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>ko gian bé_tí   quán chật_chội đông người nên ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>khi mình order đặt bánh thì nhận được sự tiếp_...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class                                    preprocess_text\n","0      1  đến quán 2 lần thôi rất là thích quán tuy nằm ...\n","1      0  đến quán vào tối chủ_nhật có band hát khá ổn t...\n","2      0  phục_vụ lâu quá mặc_dù khách rất vắng đợi gần ...\n","3      0  ko gian bé_tí   quán chật_chội đông người nên ...\n","4      1  khi mình order đặt bánh thì nhận được sự tiếp_..."]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PzegOvuxhla8","executionInfo":{"status":"ok","timestamp":1637998151811,"user_tz":-420,"elapsed":1133,"user":{"displayName":"Toàn Trần Quang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10017393319087150177"}},"outputId":"aca4910f-124a-4a63-8be7-3da3dc4b25db"},"source":["from typing import Optional\n","class SentimentData(Dataset):\n","    \"\"\"\n","    Dataset class for sentiment analysis. \n","    Every dataset using pytorch should be overwrite this class\n","    This require 2 function, __len__ and __getitem__\n","    \"\"\"\n","    def __init__(self, data_dir):\n","        \"\"\"\n","        Args:\n","            data_dir (string): Directory with the csv file\n","        \"\"\"\n","        self.df = pd.read_csv(data_dir, index_col=0).dropna().reset_index(drop=True)\n","\n","    def __len__(self):\n","        \"\"\"\n","        length of the dataset, i.e. number of rows in the csv file\n","        Returns: int \n","        \"\"\"\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        given a row index, returns the corresponding row of the csv file\n","        Returns: text (string), label (int) \n","        \"\"\"\n","        text = self.df[\"preprocess_text\"][idx]\n","        label = self.df[\"class\"][idx]\n","\n","        return text, label\n","\n","\n","class SentimentDataModule(pl.LightningDataModule):\n","    \"\"\"\n","    Module class for sentiment analysis. this class is used to load the data to the model. \n","    It is a subclass of LightningDataModule. \n","    \"\"\"\n","\n","    def __init__(self, data_dir: str = DATA_DIR, batch_size: int = 8):\n","        \"\"\"\n","        Args:\n","            data_dir (string): Directory with the csv file\n","            batch_size (int): batch size for dataloader\n","        \"\"\"\n","        super().__init__()\n","        self.data_dir = data_dir\n","        self.batch_size = batch_size\n","\n","    def setup(self, stage: Optional[str] = None):\n","        \"\"\"\n","        Loads the data to the model. \n","        the data is loaded in the setup function, so that it is loaded only once. \n","        \"\"\"\n","        data_full = SentimentData(self.data_dir)\n","        train_size = round(len(data_full) * train_ratio)\n","        val_size = len(data_full) - train_size\n","        print(len(data_full), train_size, val_size)\n","        self.data_train, self.data_val = random_split(data_full, [train_size, val_size])\n","\n","    def train_dataloader(self):\n","        \"\"\"\n","        Returns: dataloader for training\n","        \"\"\"\n","        return DataLoader(self.data_train, batch_size=self.batch_size)\n","\n","    def val_dataloader(self):\n","        \"\"\"\n","        Returns: dataloader for validation\n","        \"\"\"\n","        return DataLoader(self.data_val, batch_size=self.batch_size)\n","\n","# Do some Test with data\n","if __name__ == \"__main__\":\n","\tdm = SentimentDataModule(DATA_DIR)\n","\tdm.setup()\n","\tidx = 0\n","\tfor item in (dm.train_dataloader()):\n","\t\tprint(idx)\n","\t\tprint(item)\n","\t\tidx += 1\n","\t\tif idx > 5: break\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["27000 5400 21600\n","0\n","[('quán này mình ăn cả 2 năm nay rồi tuy_nhiên mới gia_nhập gia_đình fody nên giờ mới có cơ_hội review địa_điểm khá dễ tìm tuy_nhiên quán nằm trên dốc ngự_bình   nên nếu đi xe_máy thì không sao chứ đi xe_đạp mà lên đây ăn thì hơi nhác view bình_thường lần đầu_tiên vào đây mình khá ấn_tượng bởi cái bảng trên đó vinh_danh   nhưng danh_nhân ăn_chay trên thế_giới quán nhìn sạch_sẽ thoáng mát tuy_nhiên nếu đến đây vào ngày rằm mồng 1 thì khác chật_chội và nhìn hơi bẩn phục_vụ tạm ổn giá_cả chất_lượng quán này là sự kết_hợp của cả 3 yếu_tố ngon bổ rẻ giá thì rẻ mà thức_ăn lại rất ngon vì_vậy mình mới là khách quen của quán', 'hôm rồi mình có đi dạo trên vỉa_hè bạch_đằng thì bắt_gặp những chiếc xe_đạp hồng khá dể thương để_ý kỉ thấy nó bán cafe và kem dọc con đường này mình có gọi thử 2 cây kem kem có 23 vị mà mình chọn socola cô bé bán hàng rất bài_bản bắt kem trên cây ốc quế xịt socôla còn gói thêm cho mình ít giấy_ăn cô bé còn gởi mình card kèm số đt để gọi khi cần thật_sự dịch_vụ bán kem lưu_động này khá hay đi dạo dạo thèm cây kem ly cafe có_thể gọi và giao tận nơi ngồi ghế đá ngắm sông hàn được ăn cây kem giao tận nơi mà ko phải đi xa thì quá tuyệt rồi 1 cây 8k cũng ok', '  không_gian thoáng mát 2 cái chưa tốt phong_cách phục_vụ dở là quán nướng mà mình nhờ các bạn nướng trong bếp thì các bạn nói không được vì quán đang đông mình nhìn qua thì khách chỉ chiếm 13 số_lượng bàn món ăn không ngon thịt bò dai khẩu_phần nhỏ so với giá khi gọi món lẩu cá_lăng măng chua giá 205 0 thì chỉ có lẩu mà không có thêm các món ăn kèm như rau hay bún lúc mình gọi thêm bún thì bún đem ra vẫn còn lạnh và cứng', 'quán có không_gian rộg rãi tuy nhậu trong nhà nhưng vẫn thoải_mái như ngồi ngoài đường nhân_viên trẻ nên phục_vụ rất nhiệt_tình lên món khá nhanh chỉ có_điều là bếp nướng có vỉ nướng khá thưa nên thịt dễ bị lọt xuống dưới bếp lẩu lâu sôi lắm bù lại lẩu vừa rẻ vừa ngon quán có cây đàn guitar cả đám trong khi đợt thịt chín ngêu ngao mấy bài cũng zui 6 người đi ăn no_nê cũng chỉ có 10k người sẽ quay lại đây típ hehe', 'con_gái thích ăn crepe với uống trà thái ở đây lắm cá_nhân mình k thích mấy đồ cho giới trẻ thế_này nhưng con_gái thích quá nên 2 mẹ_con cũng hay đến đây ăn kem dừa và xôi xoài khá ngon crepe hơi ngọt tí nhưng được_cái thơm và trái_cây tươi late và capu uống được so với giá rẻ như_thế thì chất_lượng đồ_ăn cũng vừa tầm rồi', 'đi vũng_tàu mình và đám bạn cũng hay ghé đây chơi biliards nói_chung là giá rẻ bất_ngờ và chơi thoải_mái bị cái restrom chỉ có 1 phòng duy_nhất 1 nam 1 nữ hà hơi bất_tiện cái đó thôi còn nước_nôi với biliards thì ok cực', 'quán bài_trí dễ_thương và crepe cũng rất ngon mình và bạn mình kêu crepe với kem socola và dâu rất vừa_miệng đồ uống không ngon lắm nhưng cũng khá ổn d_chỉ tiếc là thái_độ nhân_viên không được thân_thiện lắm nên mình hơi không thoải_mái', 'quán thoáng mát trang_trí đẹp ấn_tượng nhất_là nhà_vệ_sinh có nguyên chùm đèn pha_lê rất đẹp và có cả máy_lạnh nữa nước uống cg ngon mà giá_cả cũng hợp_lý view đẹp khỏi chê 3'), tensor([1, 1, 0, 1, 1, 1, 0, 1])]\n","1\n","[('mình có mua ở đây vài lần rồi chất_lượng thì lúc này lúc khác nhưng lần cuối không mua nữa_là do cách nói_chuyện của chủ tiệm có_vẻ ko cần khách chỗ này tai_tiếng nhiều rồi thấy sặc_mùi tự pr bánh thì cũng bình_thường nhưng chủ tiệm nói_chuyện chảnh ngất_ngây luôn', 'xôi ngon ăn của cô từ cấp 2 xin cô nước nhiều cô cho cực_kì nhiều luôn thích ăn của cô nhất', 'nhóm mình hôm_nay đi 8 người đến geylang vào lúc 1h trưa vì mẹ và các dì mình muốn ăn dimsum mặt_khác mình được giới_thiệu là chỗ này cũng ok lắm nên mới dẫn mọi người đi ai dè chất_lượng đồ_ăn ở đây quá tệ _ mình rất thích me_goreng  mì xào malay   nên gọi một đĩa khi nv dọn ra cọng mì cứng_ngắc chưa chín cắn đôi còn thấy bột trắng ở giữa mình kêu nv để giải_quyết thì nv lơ lơ rồi bảo mì nó như_vậy đó chị xin_lỗi mình ăn me_goreng ở bên sing nhiều lần r và mì của nó k cứng như_vậy sốt xào cũng ngon hơn nhiều một dĩa mì 125k mà toàn mì sống như_thế là k đáng _ khi nv dọn dimsum mình phụ kéo dĩa đã ăn trc đó qua một bên thì nv nói dọn qua lẹ dùm tới má mình còn chưa nói với mình như_vậy _ trong dĩa sủi cảo của mình còn có một con sinh_vật lạ nhỏ nhỏ đen_đen thấy cả chân hình_như côn_trùng lúc đó mẹ mình kiểu thôi kệ đi lẹ lẹ còn về _ cháo ếch gỡ gỡ lại một_tí cháo nấu ngon và là món đỡ nhất trong số những món được gọi ra _ vì thái_độ nv quá chán nên nhà mình ăn cho có r tính tiền bỏ_qua quán mì pontian kế bên biết vậy ngay từ đầu ăn quán kế bên cho_rồi  ', ' ở ngoài nhìn vô có_khi còn đi quá luôn đó chứ k có nổi_bật j vào trong rộng_rãi dễ_thương chỗ ngồi thoải_mái rất là sáng học bài là chuẩn luôn v nhà_vệ_sinh rất là sạch_sẽ luôn mấy bạn nhân_viên nhiệt_tình cưng dễ_sợ luôn mà_còn đẹp_trai xinh gái k nữa chớ nước uống thì cũng bình_thường thôi hà', 'quán này bán phở theo kiểu nhật mì udon với_lại vài món khác phở thì vẫn là bánh_phở việt nam nhưng đồ_ăn kèm thì kiểu nhật ăn thấy không ngon với_lại nhạt quá udon thì udon thịt heo với cà_ri gà ăn cũng không sự khác_biệt giữa hai loại nước mì và đồ_ăn kèm cũng không ngon quán phục_vụ theo kiểu lựa món rồi tính tiền sau đó vô bàn ngồi đợi phục_vụ có nhiều loại nước_chấm tuy_nhiên không pha sẵn mà có bàn hướng_dẫn để pha nước_chấm theo từng loại thức_ăn nên hơi rối đánh_giá chung thì không ngon nên mình sẽ không quay lại', 'hôm_qua mình và người_yêu mới đi 27 đi tầm 8h tối quán đông kín chỗ nhân_viên thân_thiện và nhanh_nhẹn bản_thân cảm_thấy kem có_vẻ mau tan hơn trước mình ăn choco tea nhưng không thấy mùi trà xanh cho lắm thấy ngọt gắt choco khá nhìu nhưng dâu chuối khá ổn d riêng bản_thân ăn xong là thấy ngán và no căng ăn_không hết 1ly smal chắc bao_tử nhỏ', '  giá mềm chỉ 10k cổng nước được ngắm nhìn nha trang thật tuyệt_vời không_gian đẹp hiện_đại', 'thích 1 cái là dàn âm_thanh và không_gian rộng trà sữa cũng ngon'), tensor([0, 1, 0, 1, 0, 0, 1, 1])]\n","2\n","[('mình ăn một lần duy_nhất ở quán này mình vốn thích tôm nướng muối ớt nhưng ôi_thôi lần đó quán cho mình nguyên một dĩa bủn_nhủn tôm chết hương_vị không_thể_nào cứu_vãn ăn xong mình bỏ chạy luôn không_bao_giờ quay lại', 'bánh o ngon chỉ đuợc rẻ nge phong_phanh là cj huong chỉ đứng làm bình_phong chứ bánh là nguời khác làm', 'gà nướng phô_mai siêu ngon lại giá_cả phải_chăng 1 suất đủ cho 4ng ăn bình_thường 3ng nếu ăn khỏe  ăn trưa mỗi ng hết có tầm 150k mà lè lưỡi vì no luôn mỗi cái đi ăn sớm trc 1h thì_phải chờ hơi lâu', 'thấy đứa bạn cùng lớp đi rồi về bảo ngon lắm không biết thế_nào để bảo giờ đi thử rồi về lại viết fedback cho quán tiếp nhé hy_vọng không làm mình thất_vọng', 'đổi vị thấy quán sang mà giá cũng ok nên rủ bạn qua ăn món bánh_nếp nhân thịt gà ngon vỏ bánh giòn không ngán lắm nhân bên trong thịt gà ngọt nên thích món nem hải_sản ở đây cũng khá ok không phải như nem bt mà có hải_sản bên trong đc trộn vs sốt nc ăn ngon dimsum ở đây giá không đắt lắm nhưng ăn cũng ổn chỉ có món mì xào cay tứ xuyên không đậm vị lắm cũng ko được cay như mong_đợi', 'mới mua về ăn xong cảm_nhận là ăn lạ_miệng có_điều k hấp_dẫn lắm như bạn kia review chắc do khẩu_vị mình hơi khó_chịu quá 1 bịch là 35k gồm 1 xấp bánh_tráng 1 bịch muối 1 bịch chà bông 1 bịch bơ và 1 bịch sốt me trộn 4 thứ vào ăn chung sẽ có cảm_giác béo_béo chua_chua mặn mặn hoà_trộn lẫn nhau nói thật đối_với những người bụng yếu như mình thì ăn xong hơi ngại thật đây chỉ là ý_kiến riêng của mình mong mọi ng bỏ_qua nếu có gì phật_ý ah phải khen khâu bao_bì quả_là đẹp và dễ_thương lắm', 'ôi lần đầu_tiên ăn bánh cá mà như bị hớp_hồn luôn tiếc là ngon quá nên ăn_không còn để chụp ảnh nữa ghiền nhất_là bánh cá vị phô_mai ngon không_thể cưỡng thấy bánh cũng rẻ 6k cái', 'mình ngồi quán này hôm cn vừa_rồi vì phát_hiện ra gần nhà chài ơi sao mà nó ầm ỹ vậy ngồi trong khu đọc sách mà trẻ_con hét hò người_lớn nói_chuyện nhạc cũng to tóm_lại là chả thích_hợp để đọc sách gì cả hơi thất_vọng quá mình hi_vọng kiếm ra 1 chỗ yên_tĩnh để đọc sách được mà hơi bị đồ uống thì cũng bình_thường giá phải_chăng chưa trải_nghiệm đêm nhạc ở đó nên là chưa có biết'), tensor([0, 0, 1, 0, 1, 0, 1, 0])]\n","3\n","[('thấy trên mạng giới_thiệu nhiều ăn được quay xúc_xắc 10 là quay số nào cũng có thưởng nhưng mình thấy đồ_ăn cũng bình_thường gọi tới món nào thì món đó hết dù mới 1h trưa', '  meantwinsfod địa_điểm thường_xuyên ghé mỗi khi thèm bánh ngọt mình chỉ ăn bánh vì đồ uống ngoài trà sữa ra không có gì ngon xuất_sắc hết bánh hơi đắt nhưng đúng là đắt_xắt_ra_miếng ấy', 'được hôm vợ muốn ăn ốc 2vc đến gọi 1 nem 1 ốc 2 trà đá 180k quá đắt so với vỉa_hè rồi', 'chắc tại ăn k quen nên k thấy ngon lắm hơi ít nc và k đc nóng lắm tôm trông k đc tươi', 'đặt vé xem phim đến trễ 1p vì phải đứng chờ xếp_hàng lâu chứ k phải m đến trễ mà bán mất lun ghế mình đã đặt khuyến_mãi bắp thì bắp mềm xèo nhạt_nhẽo _     tiền nào của đấy quả đúng k sai rút kngiem nên mk baoh mua bắp đc sale', 'nói_chung là nghe tiếng bạn í hơi mắc nên cũng ngại mua lắm nhưng khi tới nhìn thì cái bụng nó kêu quá nên đành_lòng mua thôi tận 30k 1 cái nhưng_mà được_cái rất nhiều vị và đẹp_mắt chọn 1 e vị đào ăn vào rất thơm mùi ngọt thanh nhẹ chứ không nồng rất ngon luôn ạ ở đay còn có hộp đem về rất xinh hợp để làm_quà tặng lắm mọi người ơi chỉ có_điều phục_vụ hơi chậm thôi à nếu khách đông thì_phải chờ hơi lâu', '  nhân_viên phục_vụ chậm_chạp hay đầu_bếp chậm_chạp thì không biết chứ lúc mình tới quán ko đông bao_nhiêu mà đợi thịt ba_chỉ nướng 20p ăn xong ngồi đợi cái lẩu 10p và dành 30p ngồi bấm điện_thoại đợi bò nhúng ớt nhân_viên không thân_thiện khói nhiều đồ_ăn giá bình_thường chứ không rẻ vì mình thấy chất_lượng đồ_ăn cũng_như 1 số quán khác nhưng giá có cao hơn tính tiền cũng lâu cần cải_thiện để tồn_tại lâu hơn_nữa', 'quán đã đóng_cửa được vài tháng nay mọi người tìm quán khác xung_quanh nhé'), tensor([0, 1, 0, 0, 0, 0, 0, 0])]\n","4\n","[('mình ăn lần 1 ở đây thấy ok nên quay lại lần 2 đến lúc 1h trưa quán vắng_tanh nhân_viên tụ_tập chơi_bời hú hét còn khạc nhổ nữa quá tởm_lợm trong viên thịt còn có lông quá chán', 'giá khá là đắt thức_ăn thì ướp vừa_miệng ngon nhất_là xúc_xích và bò lá_lốt ở đây ngoài xiên que nướng ra thì_có lẩu tự chọn nữa đối_với lẩu tự chọn thì giá khá mềm chỉ có 68k thôi vị_trí không quá khó tìm đâu nhé cái bạn tuy_nhiên không_gian thì ko đc đẹp cho lắm tuy là ở vỉa_hè nhưng trời mưa thì hơi bất_tiện các bạn không nên ghé quán này vào mùa mưa 3 nhân_viên phục_vụ từng bàn thì_có nhưng có_vẻ không đc tận_tình là mấy mình xin thêm tương_ớt và ớt xanh cũng phải đợi lâu mà cũng chỉ đem ra mỗi ớt xanh cho bọn mình muốn ăn thì các bạn phải nướng thức_ăn lên đó là điểm đặc_trưng của quán nướng vỉa_hè tuy_nhiên nếu các bạn gọi nhiều món ra thì cần phải có 2 bếp mới đủ để nướng chứ 1 bếp nướng sao kịp xin thêm 1 cái bếp cũng phải đợi hết mùa luôn hơi chán về khâu phục_vụ gửi xe thì fre tuy_nhiên nhân_viên giữ xe_hơi chảnh và đợi lấy xe cũng lâu nữa à các bạn nên đi vệ_sinh trước khi đến quán này nhé vì muốn đi vệ_sinh ở đây các bạn phải cuốc_bộ 3 tầng lầu mới có nhà_vệ_sinh cho các bạn dùng 3', 'đi thứ 2 với giá khuyến_mãi 230k nhưng đồ_ăn rất tệ và kiểu như làm cho có tôm k tươi đồ_ăn nguội k đáng_giá tiền để bỏ ra món ăn quá bình_thường như bắp xào hột_vịt_lộn       nếu ngày thường k giảm_giá thì ai sẽ bỏ ra 4 50k ăn như_thế', 'mứt việt quất sữa_chua đá xay ngon tuyệt vị việt quất chua_chua vị kem ngậy ngậy 3 _   không_gian tầng 1 hẹp nhưng lên tầng2 thích cực mình thích 2 bức tranh vẽ trên tường ở đây ps lần nào lên đây cũng đc nghe 2 bài thu cuối vs tình_yêu màu nắng 3', 'mình ăn_ở đây từ nhỏ tới lớn và nhận thấy càng lúc càng dở lúc xưa ăn thích nhất_là pate và chà bông gà được cho thêm vào bánh_mì giờ thì hương_vị không còn như xưa và giá thì lại không bình_dân', 'hôm_nay thèm sushi mấy nhỏ bạn rủ đổi gió ở nhà_hàng sushi mới được đánh_giá cao trên fody quả_là rất ngon không_gian quán trang_trí rất dể thương và có rất nhiều truyện nhật ai học tiếng nhật chắc sẽ rất thích phục_vụ lại nhiệt_tình tụi mình còn được giới_thiệu nhiều loại sushi được yêu_thích của quán nữa ngon_nhất là sushi cá_hồi cuộn bơ rất béo và tươi sushi cá_hồi cuộn phô_mai chiên giòn cũng không thua_kém khi mang lên sushi còn nóng_hổi sợi phô_mai tan chảy trên miếng sushi nhìn là muốn ăn_liền sushi cuộn lươn nhật thịt dầy cùng_với nước sốt rất đậm_đà và ngon mình sẽ ghé quán thường suyên để thử thêm nhiều món ngon nữa vì menu rất nhiều món mà giá thì rất sinh_viên chất_lượng không hề thua_kém những nhà_hàng sushi có_tiếng nhưng giá chỉ băng 12 thôi ai ghiền sushi giống mình thì nên đổi gió ở đây', 'quán có view đẹp ngồi ngoài_trời thoáng_đãng không_khí rất thích ngày thu ngồi đây cực ưng tuy đồ uống giá hơi cao nhưng đc cái nv cũng dễ_chịu còn tặng bánh_quy nữa ps giá trên thực_đơn chưa bao_gồm 5 phí phục_vụ ạ', 'trà sữa tạm dc hơi ngọt nên mau ngán à mà mình gọi thêm 2 viên thạch phô_mai nhưng trong ly mình chỉ có 1 viên _  '), tensor([0, 0, 0, 1, 0, 1, 1, 0])]\n","5\n","[('lâu_lâu mới quay lại thấy có menu mới ăn thử chảo bò bằm cuộn phô_mai thì thấy siêu chán ko thấy phô_mai cũng_như chút vị phô_mai trong viên thịt bò cả cửa_hàng giờ cũng bảo kh mua giấy ướt chứ ko dùng giấy_ăn thường cũng thấy khá bất_tiện', 'rất thik pasio vì đồ uống ngon những đồ nhiều đá như chiler thì kể_cả tan hết đá cũng k bị nhạt soda cũng rất thơm x đồ nóng thì uống có_vẻ hơi nhạt không_gian thoáng yên_tĩnh mà thiết_kế nhiều cửa_sổ nên mình càng thik k bị quá đông vì bàn kê rất thoáng favorite spot mỗi khi cần đi cafe', 'theo như cảm_nhận của mình gà ở texas ngon hơn các hệ_thống thức_ăn nhanh khác thịt gà thấm không khô như ở kfc tuy_nhiên vẫn là gà_công_nghiệp nên thịt vẫn bở không ngon như gà ta menu ở đây không đa_dạng như các hệ_thống khác ví_dụ như đa_số các combo đều đi chung với món banh quy bơ không_thể đổi thành món khác được mà thật_sự món bánh_quy ở đây không ngon rât dễ ngán mình đi rất nhiều lần và thấy các bàn bên_cạnh bỏ bánh_quy bơ còn nguyên chưa đụng đến rất nhiều rất là lãng_phí tương_ớt và tương cà ở đây không ngon tương_ớt không cay mà có cả vị chua_chua ngọt ngọt của tương cà giá_cả thì mình thấy mềm hơn những quán khác không_gian máy_lạnh rộng_rãi nước uống độc_đáo thu_hút khách ở chỗ là tự châm liên_tục uống thoải_mái và có_thể mang về có coca 7up fanta và nước_lọc giữ xe miễn_phí nhân_viên phục_vụ vui_vẻ', 'quán này đã đóng_cửa giờ thay bằng quán nướng khác rồi', 'một ngày chán_chường chằng biết làm_gì   chẳng biết đi đâu hết lang_thang rồi đến đây nhìn bên ngoài có_vẻ sang_trọng cứ tưởng nhà_hàng hông à thì_ra là quán cafe ăn món sang chảnh đây cho một ngày hết chán là lá la được_cái nhân_viên phục_vụ nhiệt_tình thích thế', 'tam_đảo lạnh về đông mát_mẻ về hè thích mê ở các khách_sạn có_thể nhìn xuống vĩnh phúc lung_linh thích mê yêu những gì giản_dị nhất', 'mình vào 1 lần duy_nhất vào buổi tối gọi 1ly punch nge lạ ăn vào thì cũng_như kem bt có khác là thêm mấy vị lạ thêm chip chip vs đá viên vô trog khong gian quán thì ko phải là đẹp nên bỏ ra 45k để ăn1 ly kem mình thấy ko đág', 'không tiếc lời hoa_mỹ dành cho runam   đẹp từ mọi góc từ nội_thất đến món ăn một nét riêng rất độc_đáo và lãng mạng lần vừa_rồi mình đi cùng nhóm bạn lần sau nhất_định sẽ dẫn gấu đi cùng không_gian từ vườn ngoài bước vào bên trong lối kiến_trúc hiện_đại pha lẫn cổ_điển nhưng luôn đồng_điệu từng chi_tiết tạo cho người đứng giữa không_gian cảm_nhận rõ_rệt sự sang_trọng đầy tinh_tế bước qua khỏi gian phòng sang_trọng gặp ngay một khu vườn nhỏ đã có chừng 3 bàn khách đang cà_phê dưới đèn_vàng óng_ánh hắt ra từ bên trong nhà đầy lãng mạng đi men lối cầu_thang trên lầu thì_phải o tròn miệng đầy ngạc_nhiên hẳn như một vườn cổ_tích với đầy lá cây_xanh đèn li_ti bao quanh rèm trắng đan_xen xung_quanh ghế_ngồi chỉ nhìn thôi nhé mà đã vương_vấn rồi fod ấn_tượng là những tên món ăn rất_đỗi bình_dân nhưng chắc_chắn chất lương sẽ không làm_khách phải tiếc đồng nào cho những món tưởng rằng bình_dân như tên của nó trà xoài đào vải trà mix với xoài đào vải vị trà đắng nhẹ thơm hòa_quyện trái_cây tươi có một xíu chua_chua món nước làm kích_thích vị_giác khi dùng kèm với món mặn bánh_tráng nướng bánh_cắt hình_tam_giác đặt trên chiếc mo dừa dài ăn kèm là nước_mắm pha bánh_tráng giòm rụm mỡ hành ruốt vàng vị rất đăc trưng không giống bánh_tráng lề_đường xíu nào đâu nhé 8 loại filo   cực_kỳ xinh_đẹp phần ngon cũng không kém_cạnh mỗi loại là một nhân khác_nhau thịt bâm   cải_xong lớp da bánh dai giòn bánh hamburger mini siêu cute bột chiên runam   nghe danh món bột chiên thần_thánh ở đây đã lâu quả_nhiên là không hổ_danh lớp bạch_tuộc tươi_roi_rói giòn_tan gia_vị nêm nếm rất vừa_miệng ăn kèm nước_tương và đu_đủ bào bạch_tuộc nướng satế món này chỉ dùng phần ngon nhất của con bạch_tuộc để nướng satế thơm_lừng thấm vào bên trong vị ngọt tự_nhiên là điểm ngon nhất của món này tai heo chiên giòn vị lạ rất rất ngon giòn sừn_sựt   chấm muối_tiêu chanh món nên thử khi đến đây salad_parma   rau củ bóp giòn ngọt ăn kèm với thịt muối cắt lát kiểu ý nên thử món này trãi đều hạt thông salad rất đặc_biệt của quán vị chua_chua ngọt ngọt ko làm ngấy tí nào matcha_afogato   ngon muốn xĩu món này ăn nhanh_nhanh nhé matcha thơm cực rưới ít cà_phê lên_lớp whiping cream bên trên và thưởng_thức cokie ở đây tự làm_nên không giống bên ngoài ăn thử kèm với caphe một lần nhé nhé sau buổi ăn ngày hôm ấy cả nhóm mình đều hứa_hẹn sẽ quay lại nhiều nhiều lần nữa vì_ru nam quá đẹp đẹp một_cách kiêu_hãnh làm say lòng khách đáng để thử ít_nhất dù chỉ một lần hẹn_ru nam ngày gần nhất nhé'), tensor([0, 1, 0, 0, 1, 0, 0, 1])]\n"]}]},{"cell_type":"markdown","metadata":{"id":"gJjb04m0nGBX"},"source":["# Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255,"referenced_widgets":["6155b0f80eed456c9a886d25dbaf73a3","32f814cd1082446abefce720ef52d67a","74c435374400457dac952b175c658cb7","a4c5c0d0a9354741a21d93e39ff96575","1f8050def6404f888e2f63dc6c5072e9","8195e47994d24def8e282d00693edb9c","51834f5e17394c6d9cc09500184ff0b9","d50dc48b246e4786bda8a23947fdfff4","4bb54036a494493b907c06e479b25d13","3705ae0221044ef3b1ff8e508d8727c6","b553a3e515be4df2a1856423c2dc3163","8c79a8fa3a21414f9c2e12507afcc41c","e64ea438774f408fb797ef20605f389c","638565d28f3543e689fdb433af8702d7","eb0b064882004b13b398573a05e46d23","82cfca53e7604b8a9a256db42beac14d","ee24a25ae9e5464dbb6c1883ff395795","1c56bd8840354d3d9e4926ab83b5dfb3","8d3c50ed94254ea2be65eb6322286ccc","739d78e720ec4757bfa16147dfdb274e","c8ad38a9ea8941418c0fb8b8350abbe3","14ad0fbda45f4a07a00f2667b72e491e","14a392244246465a9379c87329806441","568be31fddf54ba380bad70a8aff6a13","c4c6e99e5a40432293afcb41b944c945","6b85a57dacf7429a93a3f18c13da41fe","58ea457b4c3b4c4bb792eae5e5f4c1a6","561879b1dd4d431dabf8b721a56c5d69","9f11c16dd809439ebff49b540fb36f6b","216cb0d635e44711b0378a5046b70ffc","cd4351dad6e647b7a61f46ed200000ee","b7853c3816a14e92b65db37e6d140595","c6ffd057653a4dc78be6c86c2f66f9c5","37ab34d15e9440599596eefcd50f821f","f4fca351c45c4459a40faf81fea66780","887912e7abcd4c2098b1f06c555da743","940f0bb356494db28404f6fc3e3737a1","e1d218f17aa9443bb477d423d1b4d90b","89e387fca2e14f0780277e2f614c7a0d","8e6dbd33a9fb4b4681e9abd976e7d2e7","5919c26d058549eaba67d4c2e3a28845","ef45cbdb95bd4e46a411f85d5b69c708","a553ea8e6ba64a2587a46c853f6db991","60533a36c4014783bbf200bfcaf55a7b"]},"id":"sypO4qMvnwOL","executionInfo":{"status":"ok","timestamp":1637998193784,"user_tz":-420,"elapsed":41985,"user":{"displayName":"Toàn Trần Quang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10017393319087150177"}},"outputId":"39d4595a-ab73-4658-c161-1adc598abd17"},"source":["from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n","tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n","mbert = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6155b0f80eed456c9a886d25dbaf73a3","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c79a8fa3a21414f9c2e12507afcc41c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14a392244246465a9379c87329806441","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"37ab34d15e9440599596eefcd50f821f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeMfJiYBHaem","executionInfo":{"status":"ok","timestamp":1637998193785,"user_tz":-420,"elapsed":31,"user":{"displayName":"Toàn Trần Quang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10017393319087150177"}},"outputId":"6335cd6e-5f95-4ff5-e203-fa5cec24ec28"},"source":["# try to convert some text into numbers\n","inputs = [\"Tôi ghét nó\", \"Tôi thích nó\", \"Tôi quý nó\"]\n","inputs = tokenizer(inputs, return_tensors='pt',padding=True ,truncation=True)\n","print(inputs)\n","outputs = mbert(**inputs)\n","print(outputs)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[    0, 14343, 74443,    18,  3711,     2],\n","        [    0, 14343, 12186,  3711,     2,     1],\n","        [    0, 14343, 23640,  3711,     2,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1, 0]])}\n","SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0987, -0.0863],\n","        [ 0.1001, -0.0840],\n","        [ 0.1030, -0.0844]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjv3S8wdRvVa","executionInfo":{"status":"ok","timestamp":1637998193786,"user_tz":-420,"elapsed":23,"user":{"displayName":"Toàn Trần Quang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10017393319087150177"}},"outputId":"9c35c0ef-42ad-4b68-e4f6-eea235ece159"},"source":["mbert"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XLMRobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"GW03BijknFFb"},"source":["from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n","\n","\n","class SentimentRoberta(pl.LightningModule):\n","    \"\"\"\n","    SentimentRoberta class inherits from LightningModule\n","    This class is used to train a model using PyTorch Lightning\n","    It overrides the following methods:\n","        - forward : forward pass of the model\n","        - training_step : training step of the model\n","        - validation_step : validation step of the model\n","        - validation_epoch_end : end of the validation epoch\n","        - configure_optimizers : configure optimizers\n","    \"\"\"\n","    def __init__(self, lr_mbert, lr_classifier):\n","        \"\"\"\n","        Initialize the model with the following parameters:\n","            - lr_roberta : learning rate of the roberta model\n","            - lr_classifier : learning rate of the classifier model\n","        \"\"\"\n","        super().__init__()\n","        self.mbert = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\")\n","        self.tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n","        self.lr_mbert = lr_mbert\n","        self.lr_classifier = lr_classifier\n","\n","    def forward(self, texts, labels=None):\n","        \"\"\"\n","        Forward pass of the model\n","        Args:\n","            - texts : input texts\n","            - labels : labels of the input texts\n","        \"\"\"\n","        inputs = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=256)\n","        for key in inputs:\n","            inputs[key] = inputs[key].to(self.device)\n","\n","        outputs = self.mbert(**inputs, labels=labels)\n","        return outputs\n","\n","    def configure_optimizers(self):\n","        \"\"\"\n","        Configure optimizers\n","        This method is used to configure the optimizers of the model by using the learning rate\n","        for specific parameter of the roberta model and the classifier model\n","        \"\"\"\n","        mbert_params = self.mbert.roberta.named_parameters()\n","        classifier_params = self.mbert.classifier.named_parameters()\n","\n","        grouped_params = [\n","            {\"params\": [p for n, p in mbert_params], \"lr\": self.lr_mbert},\n","            {\"params\": [p for n, p in classifier_params], \"lr\": self.lr_classifier}\n","        ]\n","        optimizer = torch.optim.AdamW(\n","            grouped_params\n","        )\n","        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.98)\n","        return {\n","            'optimizer': optimizer,\n","            'lr_scheduler': {\n","                'scheduler': scheduler,\n","                'monitor': 'f1/val',\n","            }\n","        }\n","\n","    def training_step(self, batch, batch_idx):\n","        \"\"\"\n","        Training step of the model\n","        Args:\n","            - batch : batch of the data\n","            - batch_idx : index of the batch\n","        \"\"\"\n","        texts, labels = batch\n","        outputs = self(texts, labels=labels)\n","\n","        if len(outputs.values()) == 3:\n","            loss, logits, _ = outputs.values()\n","        else:\n","            loss, logits = outputs.values()\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        \"\"\"\n","        Validation step of the model, used to compute the metrics\n","        Args:\n","            - batch : batch of the data\n","            - batch_idx : index of the batch\n","        \"\"\"\n","        texts, labels = batch\n","        outputs = self(texts, labels=labels)\n","\n","        if len(outputs.values()) == 3:\n","            loss, logits, _ = outputs.values()\n","        else:\n","            loss, logits = outputs.values()\n","\n","        output_scores = torch.softmax(logits, dim=-1)\n","        return loss, output_scores, labels\n","\n","    def validation_epoch_end(self, validation_step_outputs):\n","        \"\"\"\n","        End of the validation epoch, this method will be called at the end of the validation epoch,\n","        it will compute the multiple metrics of classification problem\n","        Args:\n","            - validation_step_outputs : outputs of the validation step\n","        \"\"\"\n","\n","        val_preds = torch.tensor([], device=self.device)\n","        val_scores = torch.tensor([], device=self.device)\n","        val_labels = torch.tensor([], device=self.device)\n","        val_loss = 0\n","        total_item = 0\n","\n","        for idx, item in enumerate(validation_step_outputs):\n","            loss, output_scores, labels = item\n","\n","            predictions = torch.argmax(output_scores, dim=-1)\n","            val_preds = torch.cat((val_preds, predictions), dim=0)\n","            val_scores = torch.cat((val_scores, output_scores[:, 1]), dim=0)\n","            val_labels = torch.cat((val_labels, labels), dim=0)\n","\n","            val_loss += loss\n","            total_item += 1\n","\n","        # print(\"VAL PREDS\", val_preds.shape)\n","        # print(\"VAL SCORES\", val_scores.shape)\n","        # print(\"VAL LABELS\", val_labels.shape)\n","        val_preds = val_preds.cpu().numpy()\n","        val_scores = val_scores.cpu().numpy()\n","        val_labels = val_labels.cpu().numpy()\n","\n","        reports = classification_report(val_labels, val_preds, output_dict=True)\n","        print(\"VAL LABELS\", val_labels)\n","        print(\"VAL SCORES\", val_scores)\n","        try:\n","            auc = roc_auc_score(val_labels, val_scores)\n","        except Exception as e:\n","            print(e)\n","            print(\"Cannot calculate AUC. Default to 0\")\n","            auc = 0\n","        accuracy = accuracy_score(val_labels, val_preds)\n","\n","        print(classification_report(val_labels, val_preds))\n","\n","        self.log(\"loss/val\", val_loss)\n","        self.log(\"auc/val\", auc)\n","        self.log(\"accuracy/val\", accuracy)\n","        self.log(\"precision/val\", reports[\"weighted avg\"][\"precision\"])\n","        self.log(\"recall/val\", reports[\"weighted avg\"][\"recall\"])\n","        self.log(\"f1/val\", reports[\"weighted avg\"][\"f1-score\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":681,"referenced_widgets":["29e377876fe14fa7b947dc1410683b2e","fffc88bbb8a0441885dabd54aee869da","703cf676361b4a04ae8b8fccd35f9234","01e34898d93a4912870a0112b0ed8d52","77979da20e544e06b6c2720142d9c9bf","214ce1eea54d4c92a7f601d865b1e17a","05818affbde843938c70777addb3c7c8","189f60a0d2074f1fbf6942e032da9a1d","596aff5d44ba47709488e40ad40cffc5","d7127067aa8446b2a37c87eeba8b8e80","bad2f6a0262c46a79ef664083d4a3735","8d1052edc66745d489b8e0521b6196dd","4e261c2145d94359bc6e802cd403bd50","ab646c647ef94928a8549ebdbd214c19","4f19dd24b1934551835ccdccfec60248","ff1a1c027d6c4ca9a6f2d153643f6e10","68ca4b3edb4f4998a49f37a0d36d352b","008222609e8e44218dd7a2e1d77de8ba","d486464353dd4a8c8c2b90c329842cf2","4f50bad9552143ed91b928b74fc966a6","6a73d5f9f1c54bec8f92e5d4bf9aa325","a3611fdf5aeb4d9492a1008d985c7217"]},"id":"qMRyo5iYBvn8","executionInfo":{"status":"ok","timestamp":1637998215885,"user_tz":-420,"elapsed":21238,"user":{"displayName":"Toàn Trần Quang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10017393319087150177"}},"outputId":"b2b9f219-1ca7-4170-c46a-013348850c1e"},"source":["\n","trainer = pl.Trainer(\n","    fast_dev_run=True,\n","    gpus=1,\n",")\n","model = SentimentRoberta(lr_mbert=1e-5, lr_classifier=3e-3)\n","dm = SentimentDataModule()\n","\n","trainer.fit(model, dm)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n","Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"stream","name":"stdout","text":["27000 5400 21600\n"]},{"output_type":"stream","name":"stderr","text":["\n","  | Name  | Type                                | Params\n","--------------------------------------------------------------\n","0 | mbert | XLMRobertaForSequenceClassification | 278 M \n","--------------------------------------------------------------\n","278 M     Trainable params\n","0         Non-trainable params\n","278 M     Total params\n","1,112.181 Total estimated model params size (MB)\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:408: UserWarning: The number of training samples (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29e377876fe14fa7b947dc1410683b2e","version_minor":0,"version_major":2},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d1052edc66745d489b8e0521b6196dd","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. 1. 1. 0. 0. 1.]\n","VAL SCORES [0.562457   0.56472605 0.6174318  0.6340162  0.5688453  0.4669752\n"," 0.4944857  0.48685178]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.67      0.67      0.67         3\n","         1.0       0.80      0.80      0.80         5\n","\n","    accuracy                           0.75         8\n","   macro avg       0.73      0.73      0.73         8\n","weighted avg       0.75      0.75      0.75         8\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"0HtXPhT4g9VN"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"3dk5B2udShTU"},"source":["import torch\n","torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BfhWop6-hD08","colab":{"base_uri":"https://localhost:8080/","height":765,"referenced_widgets":["cf56bf3884364c88abc45e2844c4c590","ce3b2765eeb74a65a6b8137cecb0980f","806831da7e754f3d993d023f0228d928","0250cd1f5abd46beb22d6ba40c03f2c3","5ca8efe737c94f8dac665ee11ae020a2","2dcdac74c6724a5a855caacc57e07d97","56c26b2b432f4236a3b4efc65b04483c","1da5dd29fbb34d63983611f79568008e","f5571eb5d60646f3813f4963476ba22a","88e1d48b28614d4090e45495c4e123e6","61d3604ced8a43878bc9e16d075f4238","b4128aad184e4d4c9174d40b5ea3efbb","454f0255b64b4b9b9dbe9bd897f4b404","88b0cbe04174484abe78dcb92eada40e","6971e5e5539343769cb9130075e7da8b","23d8a90366fa4193a893cecadc6546eb","796fa4f92e5841b5a1f397e1179691e9","559fe0e992d94b99b8a9d90f5a9296cc","1e42b6d01e4847858780b0c1e05a145f","70e0c948b8fe422a8f63ed67cdf0ce65","7eb73ed1cca34e2fa27d160c754af53d","89683f285640422cba03e66b8332e643","bbc7190d1fed42e8b76dacdf4887a5c8","23c113c9a9e0424da3cbf764fdfe823f","ffeba23680074b52a45ef976f323dea3","73e2c3f57aa246b7adc6d25d9736c8da","edbb856bb3fc4a6d97b820deb94238f1","b333fd5b10d8434eb56d3ba68220d14b","4fd80b5bf00e4b9caf2deef785685721","d8ec5cb8221b4f1f820bd32991a9e834","dbd856365a0543eabd303a63de8951cb","b8ca3b1c912d43f1ac9c09ada3126362","6090a32fc8d14884a23a16a374a4be8a"]},"outputId":"4c25bc44-7461-4826-e076-7401973d70a4"},"source":["from pytorch_lightning import loggers as pl_loggers\n","from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n","import warnings\n","warnings.filterwarnings('ignore')\n","start = time.time()\n","torch.manual_seed(123)\n","\n","tb_logger = pl_loggers.TensorBoardLogger('/content/drive/MyDrive/Colabs/logsxmlr/')\n","\n","trainer = pl.Trainer(\n","    min_epochs=1,\n","    max_epochs=2,\n","    gpus=1,\n","    precision=16,\n","    val_check_interval=0.5,\n","    # check_val_every_n_epoch=1,\n","    callbacks=[\n","      ModelCheckpoint(\n","          dirpath='/content/drive/MyDrive/Colabs/ckpt',\n","          save_top_k=3,\n","          monitor='f1/val',\n","      ), \n","      EarlyStopping('f1/val', patience=5)\n","    ],\n","    fast_dev_run=False,\n","    logger=tb_logger\n",")\n","\n","dm.setup(stage=\"fit\")\n","trainer.fit(model, dm)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using 16bit native Automatic Mixed Precision (AMP)\n","GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name  | Type                                | Params\n","--------------------------------------------------------------\n","0 | mbert | XLMRobertaForSequenceClassification | 278 M \n","--------------------------------------------------------------\n","278 M     Trainable params\n","0         Non-trainable params\n","278 M     Total params\n","556.090   Total estimated model params size (MB)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf56bf3884364c88abc45e2844c4c590","version_minor":0,"version_major":2},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0.]\n","VAL SCORES [0.58962774 0.58649325 0.62337685 0.6410854  0.58752906 0.50980633\n"," 0.5351212  0.52854866 0.6466276  0.60372746 0.5990747  0.6139312\n"," 0.5842712  0.64282495 0.61199087 0.611353  ]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.00      0.00      0.00         8\n","         1.0       0.50      1.00      0.67         8\n","\n","    accuracy                           0.50        16\n","   macro avg       0.25      0.50      0.33        16\n","weighted avg       0.25      0.50      0.33        16\n","\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4128aad184e4d4c9174d40b5ea3efbb","version_minor":0,"version_major":2},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbc7190d1fed42e8b76dacdf4887a5c8","version_minor":0,"version_major":2},"text/plain":["Validating: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["VAL LABELS [1. 1. 0. ... 0. 0. 1.]\n","VAL SCORES [0.81405276 0.82876563 0.11531159 ... 0.7871551  0.1867616  0.803598  ]\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.87      0.89     10757\n","         1.0       0.88      0.91      0.89     10843\n","\n","    accuracy                           0.89     21600\n","   macro avg       0.89      0.89      0.89     21600\n","weighted avg       0.89      0.89      0.89     21600\n","\n"]}]},{"cell_type":"code","metadata":{"id":"jkq3I3DzT_qf"},"source":["end = time.time()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjN7cPJ-UAME"},"source":["end - start"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8wvJNe5xG62"},"source":["TEST"]},{"cell_type":"code","metadata":{"id":"Qo1gSkpVxO80"},"source":["# show the result here\n","%reload_ext tensorboard\n","%tensorboard --logdir '/content/drive/MyDrive/Colabs/logxmlr/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QKVQrC1TkzRG"},"source":["# test the model with some sentence\n","inputs = [\n","    \"Món ăn ngon, đồ uống ngon, rẻ\",\n","    \"Món ăn ngon, đồ uống ngon nhưng đắt\",\n","    \"Tuy rẻ nhưng đồ ăn không ngon, đồ uống không ngon\",\n","    \"không gian chật hẹp, nhân viên không nhiệt tình, đò ăn tạm được\",\n","    \"hàng rất tốt, đẹp, mẫu mã đa dạng, sẽ quay lại lần sau\"\n","  ]\n","outputs = model(inputs)\n","logits = outputs\n","score = torch.softmax(logits, dim=-1)\n","Labels = [\"Negative\", \"Positive\"]\n","numSent = len(inputs)\n","\n","for index ,item in enumerate(inputs):\n","    print(f\"The sentence: '{inputs[index]}' has {Labels[torch.argmax(score[index], dim=-1).item()]} tone with confident score : {score[index][torch.argmax(score[index], dim=-1).item()]} \\n\" )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rf2QbeIgLdy6"},"source":["SAVE_MODEL_PATH = \"/content/drive/MyDrive/Colabs/saveModel/xmlrModel.pt\"\n","torch.save(model.state_dict(), SAVE_MODEL_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z7_YanoYLvRs"},"source":["modelSave = SentimentRoberta(lr_mbert=1e-5, lr_classifier=3e-3)\n","modelSave.load_state_dict(torch.load(SAVE_MODEL_PATH))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XjuwW_lWM5kT"},"source":["# test the model with some sentence\n","inputs = [\n","    \"Món ăn ngon, đồ uống ngon, rẻ\",\n","    \"Món ăn ngon\",\n","    \"Tuy rẻ nhưng đồ ăn không ngon, đồ uống không ngon\",\n","    \"không gian chật hẹp, nhân viên nhiệt tình, đồ ăn ngon\",\n","    \"hàng rất tốt, đẹp, mẫu mã đa dạng, sẽ quay lại lần sau\"\n","  ]\n","outputs = modelSave(inputs)\n","logits = outputs\n","score = torch.softmax(logits, dim=-1)\n","Labels = [\"Negative\", \"Positive\"]\n","numSent = len(inputs)\n","\n","for index ,item in enumerate(inputs):\n","    print(f\"The sentence: '{inputs[index]}' has {Labels[torch.argmax(score[index], dim=-1).item()]} tone with confident score : {score[index][torch.argmax(score[index], dim=-1).item()]} \\n\" )\n"],"execution_count":null,"outputs":[]}]}